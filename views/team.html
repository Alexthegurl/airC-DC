<!doctype html>
<html lang="en">
<head>

  <title>AirC&#9889DC</title>
  <!-- http://www.webrtc.org/ -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
<link rel="stylesheet" type="text/css" href="/css/style.css">
<style>
  #monitor {
      display: none;
    }

    #blendCanvas {
      display: none;
    }
  </style>
</head>
<body id="team">
<table align="center">
  <tr>
    <th><a class="button" href="/drums"><button>Air Drums</button></a></th>
    <th><a class="button" href="/piano"><button>Air Piano</button></a></th>
    <th><a class="button" href="/dj1"><button>Air DJ Set 1</button></a></th>
    <th><a class="button" href="/dj2"><button>Air DJ Set2</button></a></th>
    <th><a class="button" href="/trump"><button>Trump Mode</button></a></th>
    <th><a class="button" href="/team"><button>About the Team</button></a></th>
    <th><a class="button" href="/scenes"><button>Behind the Scenes</button></a></th>
    <th><a class="button" href="/bass"><button>Air Bass</button></a></th>
    <th><a class="button" href="/index"><button>Home</button></a></th>


  </tr>
</table>

<video align="center" id="monitor" autoplay width: 1400; height: 900;></video>


<div id="canvasLayers" width="1400px" height="900px" style="margin: auto;  top: 100px; position: absolute;" align="center">
<!-- video canvas is the mirror -->
<canvas id="videoCanvas" width="1400px" height="900px" style="margin: auto;  top: 100px; position: absolute;" align="center"></canvas>

<!-- layer 2 has the button/instrument detections in them -->
<canvas id="layer2" width="1400px" height="900px" style="margin: auto;  top: 100px; position: absolute;" align="center"></canvas>
</div>

<!-- blend canvas is where all the photos are being taken in black and white and comparing the pixel changes based on diff. background image, detecting "movement" when the images are different from different motions -->
<canvas id="blendCanvas" width="1400px" height="900px" align="center"></canvas>


<div id="messageError"></div>
<div id="messageArea" style="position: relative; top: 0px;" align="center">Messages will be displayed here.</div>





<script>
      

var buttons = [];

var button1 = new Image();
button1.src ="images/Chris.png";
var buttonData1 = { name:"Chris Frazzini", email:"cfrazzin/@indiana.edu", github: "CFrazz25", image:button1, x:1100, y:150, w:300, h:300 };
buttons.push( buttonData1 );

var button2 = new Image();
button2.src ="images/Derek.png";
var buttonData2 = { name:"Derek Georgevich", email:"dgeorgevich@gmail.com", github: "DGeorgevich" image:button2, x:750, y:150, w:300, h:300 };
buttons.push( buttonData2 );

var button3 = new Image();
button3.src ="images/Alex.png";
var buttonData3 = { name:"Alex Origitano", email:"aorigitano@gmail.com", github:"Alexthegurl" image:button3, x:400, y:150, w:300, h:300 };
buttons.push( buttonData3 );

var button4 = new Image();
button4.src ="images/Brendan.png";
var buttonData4 = { name:"Brendan White", email:"brendanjwh@gmail.com", github:"brendanjwh" image:button4, x:10, y:150, w:300, h:300 };
buttons.push( buttonData4 );

var button5 = new Image();
button5.src ="images/crowd.png";
var buttonData5 = { image:button5, x:0, y:800, w:1800, h:100 };




// called in animate function
function render() 
{ 
  if ( video.readyState === video.HAVE_ENOUGH_DATA ) 
  {
    
    layer2Context.drawImage( button5, 0, 800, 1800, 100 );
    // mirror video
    videoContext.drawImage( video, 0, 0, videoCanvas.width, videoCanvas.height );
    for ( var i = 0; i < buttons.length; i++ )
      // this is where the buttons are being placed on one canvas.
      layer2Context.drawImage( buttons[i].image, buttons[i].x, buttons[i].y, buttons[i].w, buttons[i].h ); 

  }

}



// check if white region from blend overlaps area of interest (e.g. buttons)
function checkAreas() 
{
  // buttons are the images being touched
  for (var b = 0; b < buttons.length; b++) 
  {
    // get the pixels in a note area from the blended image. blendContext is the black and white canvas, the one showing the white imagery for motion movement. 
    var blendedData = blendContext.getImageData( buttons[b].x, buttons[b].y, buttons[b].w, buttons[b].h );
      
    // calculate the average lightness of the blended data
    var i = 0;
    var sum = 0;
    var countPixels = blendedData.data.length * 0.25;
    while (i < countPixels) 
    {
      sum += (blendedData.data[i*4] + blendedData.data[i*4+1] + blendedData.data[i*4+2]);
      ++i;
    }
    // calculate an average between of the color values of the note area [0-255]
    var average = Math.round(sum / (3 * countPixels));
    if (average > 50) // more than 20% movement detected
    {
      console.log( "Button " + buttons[b].name + " triggered." ); // do stuff
      messageArea.innerHTML = "<font size='+10' color='black'><b>Name: " + buttons[b].name + " email:" + buttons[b].email + " Github:" + buttons[b].github + ".</b></font>";
    }
  }
}

</script>

<script type="text/javascript" src="javascripts/music_app.js"></script>

</body>
</html>

